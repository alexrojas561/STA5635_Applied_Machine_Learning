{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TISP:\n",
    "    def __init__(self, features, lambda_, iterations = 100):\n",
    "        \n",
    "        # Initialize parameters \n",
    "        self.features = features\n",
    "        self.iterations = iterations\n",
    "        self.lambda_ = lambda_\n",
    "        self.likelihoods = []\n",
    "        \n",
    "        self.feature_lambda = [] # Container for \n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        \n",
    "        # Set up sigmoid \n",
    "        sig_z = (1/(1+np.exp(-z)))\n",
    "        \n",
    "        assert (sig_z.shape == z.shape)\n",
    "        return sig_z\n",
    "        \n",
    "        \n",
    "    def log_likelihood(self, Xw, y):\n",
    "        ''' \n",
    "        Where: wX is the dot product of the regressor matrix + parameters\n",
    "               y is the data transformed to -> {0, 1}\n",
    "               y_ are the true labels of X in space -> {-1, +1}\n",
    "               \n",
    "               \n",
    "        Loss function uses [-1, 1] labels\n",
    "        '''\n",
    "        \n",
    "        likelihood = (1/Xw.shape[0])*sum(np.log(1 + np.exp(-y*Xw))) #+ \\\n",
    "                      # self.lambda_*sum(#P(x))        \n",
    "        return likelihood\n",
    "\n",
    "    \n",
    "    \n",
    "    def cap_lambda(self, current_lambda):\n",
    "        non_zero_ind = np.where(self.weights!=0)\n",
    "        non_zero_features = len(non_zero_ind[0])\n",
    "        \n",
    "        token = \"L:\" + str(current_lambda) + '/F:' + str(non_zero_features)\n",
    "        \n",
    "        return token\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Where X is the regressor matrix\n",
    "              y are the labels {-1, +1}\n",
    "              \n",
    "        Algorithm uses [0, 1] labels\n",
    "        '''\n",
    "        num_obs = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        \n",
    "        # Start w/ zero weights\n",
    "        self.weights = np.zeros(num_features)\n",
    "        \n",
    "        # Transform y to be {0, 1}\n",
    "        y_ = np.where(y == -1, 0, y)\n",
    "        \n",
    "        for j in range(len(self.lambda_)):\n",
    "            for i in range(self.iterations):\n",
    "            \n",
    "                Xw = np.dot(X, self.weights)\n",
    "                sig_Xw = self.sigmoid(Xw)\n",
    "\n",
    "                # Try the other way later - just use the loss from logistic regression with penalty\n",
    "                gradient = np.dot(X.T, y_ - sig_Xw)\n",
    "\n",
    "\n",
    "                # Calculate weights\n",
    "                self.weights += (1/num_obs)*gradient\n",
    "                self.weights *= (np.absolute(self.weights) > self.lambda_[j])\n",
    "\n",
    "\n",
    "                # Calculating log likelihood\n",
    "                likelihood = self.log_likelihood(Xw,y)\n",
    "\n",
    "                self.likelihoods.append(likelihood)\n",
    "                \n",
    "                # Capture lambda per feature\n",
    "                self.feature_lambda.append(self.cap_lambda(j))\n",
    "                \n",
    "            \n",
    "                        \n",
    "            \n",
    "    def predict_proba(self,X):\n",
    "    \n",
    "        if self.weights is None:\n",
    "            raise Exception(\"Fit the model before prediction\")\n",
    "                     \n",
    "        z = np.dot(X,self.weights)\n",
    "        probabilities = self.sigmoid(z)\n",
    "                \n",
    "        return probabilities\n",
    "    \n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        # Thresholding probability to predict binary values\n",
    "        binary_predictions = np.array(list(map(lambda x: 1 if x>threshold else 0, self.predict_proba(X))))\n",
    "        \n",
    "        return binary_predictions\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data input\n",
    "X_train_a = pd.read_csv('data/Gisette/gisette_train.data', sep='\\s+', header=None)\n",
    "y_train_a = pd.read_csv('data/Gisette/gisette_train.labels', header=None)\n",
    "\n",
    "X_test_a = pd.read_csv('data/Gisette/gisette_valid.data',  sep='\\s+', header=None)\n",
    "y_test_a = pd.read_csv('data/Gisette/gisette_valid.labels', header=None)\n",
    "\n",
    "# Prepare data for matrix algebra\n",
    "y_train_a = y_train_a.values.ravel()\n",
    "y_test_a = y_test_a.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the variables of the training set\n",
    "scaler_a = StandardScaler()\n",
    "scaler_a.fit(X_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform both the train and test set\n",
    "X_train_scaled_a = scaler_a.transform(X_train_a)\n",
    "X_test_scaled_a = scaler_a.transform(X_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-8c598a486791>:15: RuntimeWarning: overflow encountered in exp\n",
      "  sig_z = (1/(1+np.exp(-z)))\n",
      "<ipython-input-7-8c598a486791>:31: RuntimeWarning: overflow encountered in exp\n",
      "  likelihood = (1/Xw.shape[0])*sum(np.log(1 + np.exp(-y*Xw))) #+ \\\n"
     ]
    }
   ],
   "source": [
    "features = [10, 30, 100, 300, 1000]\n",
    "lambdas = list(range(220))\n",
    "\n",
    "model_a = TISP(features = features, lambda_ = lambdas)\n",
    "model_a.fit(X_train_a, y_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Misclassification\n",
    "preds_train_a = model_a.predict(X_train_scaled_a)\n",
    "1 - accuracy_score(y_train_a, preds_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Misclassification\n",
    "preds_test_a = model_a.predict(X_test_scaled_a)\n",
    "1 - accuracy_score(y_test_a, preds_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a.feature_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
